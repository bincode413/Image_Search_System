{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70046e1",
   "metadata": {},
   "source": [
    "## ⚙️ 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1995df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  torth 설정 완료\n",
      "⚙️  class정의 완료\n",
      "⚙️  환경설정 완료\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "print('⚙️  torth 설정 완료')\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import matplotlib.pyplot as plt\n",
    "from public_function import MPerClassSampler\n",
    "print('⚙️  환경설정 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6ddc0",
   "metadata": {},
   "source": [
    "## 📊대조 학습용 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c42a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  데이타셋 로드 및 로더 정의\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # 이미지 크기 고정\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='my_dataset', transform=transform)\n",
    "sampler = MPerClassSampler(train_dataset.targets, m=4, length_before_new_iter=len(train_dataset))\n",
    "batch_size = 44\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False, sampler=sampler\n",
    ")\n",
    "print('⚙️  데이타셋 로드 및 로더 정의')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262aea7",
   "metadata": {},
   "source": [
    "## ✨모델 로드 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be7e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  기본 모델 형태 로딩 완료\n"
     ]
    }
   ],
   "source": [
    "# 기본적인 모델\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "#모델 GPU로 가능하면 옮기기\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet18()\n",
    "model = model.to(device)\n",
    "print('⚙️  기본 모델 형태 로딩 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4253f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  빠른 손실값 계산함수\n"
     ]
    }
   ],
   "source": [
    "# 빠른 손실값 계산 함수 정의\n",
    "def contrastive_loss_fast(features, labels, margin=0.3):\n",
    "    features = features / (torch.norm(features, p=2, dim=1, keepdim=True) + 1e-12).expand_as(features)\n",
    "    distance_matrix = torch.cdist(features, features, p=2)\n",
    "    labels_expanded = labels.unsqueeze(0).expand(len(labels), len(labels))\n",
    "    label_matrix = (labels_expanded == labels_expanded.t()).byte()\n",
    "    label_matrix.fill_diagonal_(0)  # Exclude self-comparison\n",
    "    same_loss = label_matrix * distance_matrix.pow(2)\n",
    "    different_loss = (1 - label_matrix) * torch.pow(torch.clamp(margin - distance_matrix, min=0.0), 2)\n",
    "    loss = same_loss + different_loss\n",
    "    return loss.mean()\n",
    "print('⚙️  빠른 손실값 계산함수')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a61a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 94%|█████████▍| 47/50 [11:52<00:46, 15.39s/it, 현재 Epoch=0, 현재 대조 손실 값=0.0353]c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:890: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 50/50 [12:39<00:00, 15.18s/it, 현재 Epoch=0, 현재 대조 손실 값=0.0359]\n",
      "100%|██████████| 50/50 [12:34<00:00, 15.08s/it, 현재 Epoch=1, 현재 대조 손실 값=0.0341]\n",
      "100%|██████████| 50/50 [12:35<00:00, 15.11s/it, 현재 Epoch=2, 현재 대조 손실 값=0.0288]\n",
      "100%|██████████| 50/50 [12:36<00:00, 15.13s/it, 현재 Epoch=3, 현재 대조 손실 값=0.0293]\n",
      "100%|██████████| 50/50 [12:32<00:00, 15.06s/it, 현재 Epoch=4, 현재 대조 손실 값=0.0289]\n",
      "100%|██████████| 50/50 [12:38<00:00, 15.17s/it, 현재 Epoch=5, 현재 대조 손실 값=0.0301]\n",
      "100%|██████████| 50/50 [12:36<00:00, 15.14s/it, 현재 Epoch=6, 현재 대조 손실 값=0.0265]\n",
      "100%|██████████| 50/50 [12:44<00:00, 15.30s/it, 현재 Epoch=7, 현재 대조 손실 값=0.0287]\n",
      "100%|██████████| 50/50 [12:38<00:00, 15.16s/it, 현재 Epoch=8, 현재 대조 손실 값=0.0220]\n",
      "100%|██████████| 50/50 [12:43<00:00, 15.27s/it, 현재 Epoch=9, 현재 대조 손실 값=0.0222]\n",
      "100%|██████████| 50/50 [12:43<00:00, 15.28s/it, 현재 Epoch=10, 현재 대조 손실 값=0.0225]\n",
      "100%|██████████| 50/50 [12:37<00:00, 15.15s/it, 현재 Epoch=11, 현재 대조 손실 값=0.0232]\n",
      "100%|██████████| 50/50 [12:33<00:00, 15.07s/it, 현재 Epoch=12, 현재 대조 손실 값=0.0211]\n",
      "100%|██████████| 50/50 [12:33<00:00, 15.08s/it, 현재 Epoch=13, 현재 대조 손실 값=0.0228]\n",
      "100%|██████████| 50/50 [12:40<00:00, 15.21s/it, 현재 Epoch=14, 현재 대조 손실 값=0.0207]\n",
      "100%|██████████| 50/50 [12:38<00:00, 15.18s/it, 현재 Epoch=15, 현재 대조 손실 값=0.0186]\n",
      "100%|██████████| 50/50 [12:46<00:00, 15.34s/it, 현재 Epoch=16, 현재 대조 손실 값=0.0187]\n",
      "100%|██████████| 50/50 [12:42<00:00, 15.24s/it, 현재 Epoch=17, 현재 대조 손실 값=0.0191]\n",
      "100%|██████████| 50/50 [12:27<00:00, 14.95s/it, 현재 Epoch=18, 현재 대조 손실 값=0.0170]\n",
      "100%|██████████| 50/50 [12:31<00:00, 15.04s/it, 현재 Epoch=19, 현재 대조 손실 값=0.0168]\n",
      "100%|██████████| 50/50 [12:33<00:00, 15.06s/it, 현재 Epoch=20, 현재 대조 손실 값=0.0165]\n",
      "100%|██████████| 50/50 [12:23<00:00, 14.86s/it, 현재 Epoch=21, 현재 대조 손실 값=0.0172]\n",
      "100%|██████████| 50/50 [12:30<00:00, 15.02s/it, 현재 Epoch=22, 현재 대조 손실 값=0.0165]\n",
      "100%|██████████| 50/50 [12:30<00:00, 15.02s/it, 현재 Epoch=23, 현재 대조 손실 값=0.0177]\n",
      "100%|██████████| 50/50 [12:32<00:00, 15.05s/it, 현재 Epoch=24, 현재 대조 손실 값=0.0164]\n",
      "100%|██████████| 50/50 [12:33<00:00, 15.07s/it, 현재 Epoch=25, 현재 대조 손실 값=0.0155]\n",
      "100%|██████████| 50/50 [12:30<00:00, 15.00s/it, 현재 Epoch=26, 현재 대조 손실 값=0.0149]\n",
      "100%|██████████| 50/50 [12:30<00:00, 15.02s/it, 현재 Epoch=27, 현재 대조 손실 값=0.0160]\n",
      "100%|██████████| 50/50 [12:25<00:00, 14.90s/it, 현재 Epoch=28, 현재 대조 손실 값=0.0144]\n",
      "100%|██████████| 50/50 [12:30<00:00, 15.00s/it, 현재 Epoch=29, 현재 대조 손실 값=0.0155]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  학습이 완료됨\n",
      "💾 모델이 'trained_model.pth' 파일로 저장되었습니다!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 30\n",
    "margin = 0.75\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.0001)\n",
    "for i in range(epoch):\n",
    "    progress_bar = tqdm(train_dataloader)  # 진행바를 출력하여, 학습 과정을 눈으로 보기 쉽게 만들어 줍니다!\n",
    "\n",
    "    for data in progress_bar:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        features = model(images)\n",
    "        loss = contrastive_loss_fast(features, labels, margin)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_postfix({\"현재 Epoch\": i, \"현재 대조 손실 값\": f\"{loss.item():.4f}\"})\n",
    "print(f'⚙️  학습이 완료됨')\n",
    "\n",
    "torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "print(\"💾 모델이 'trained_model.pth' 파일로 저장되었습니다!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
